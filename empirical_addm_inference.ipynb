{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319397cd",
   "metadata": {},
   "source": [
    "# Empirical aDDM Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec06fc0f",
   "metadata": {},
   "source": [
    "This notebook will simulate and recover data using `efficient-fpt`'s pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57174051",
   "metadata": {},
   "source": [
    "### Simulating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef12f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "DDM_dir = os.path.abspath('/Users/bchien37/Desktop/Enkavilab/DDM')\n",
    "sys.path.append(DDM_dir)\n",
    "\n",
    "dt = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b331bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import get_corrected_empirical_distributions\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_csv('/Users/bchien37/Desktop/Enkavilab/DDM/1ms_trial_data.csv')\n",
    "df_raw['choice'] = df_raw['choice'].map({'left':0,'right':1})\n",
    "df_raw['RT'] = df_raw['RT'] / dt # adjustment for RT\n",
    "df_raw['fixation'] = df_raw['fixation'].apply(literal_eval)\n",
    "\n",
    "to_drop = pd.read_csv(\"/Users/bchien37/Desktop/Enkavilab/DDM/dropped_trials.csv\").rename(columns={\"parcode\": \"sub_id\"})\n",
    "\n",
    "df = df_raw[\n",
    "    ~df_raw.set_index([\"sub_id\", \"trial\"]).index.isin(\n",
    "        to_drop.set_index([\"sub_id\", \"trial\"]).index\n",
    "    )\n",
    "]\n",
    "\n",
    "num_data, _ = df.shape\n",
    "\n",
    "value_diffs = np.unique(df['avgWTP_left'] - df['avgWTP_right'])\n",
    "legend = {\n",
    "    \"left\": {1},\n",
    "    \"right\": {2},\n",
    "    \"transition\": {0}, \n",
    "    \"blank_fixation\": {4}\n",
    "}\n",
    "fixation_col = 'fixation'\n",
    "left_value_col = 'avgWTP_left'\n",
    "right_value_col = 'avgWTP_right'\n",
    "\n",
    "empirical_distributions = get_corrected_empirical_distributions(\n",
    "    df,\n",
    "    value_diffs=value_diffs,\n",
    "    legend=legend,\n",
    "    fixation_col=fixation_col,\n",
    "    left_value_col=left_value_col,\n",
    "    right_value_col=right_value_col,\n",
    "    cutoff=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f753afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "a, b = 2.1, 0.3\n",
    "eta = 0.5\n",
    "kappa = 2\n",
    "T = a/b / dt # Bounded by Markov w/p 0.9, E[T] = 2.5, in this case, in ms\n",
    "x0 = 0\n",
    "sigma = 0.7 # As calculated from Eum et al. (2023)\n",
    "\n",
    "# r1_data = np.zeros(num_data)\n",
    "# r2_data = np.zeros(num_data)\n",
    "r1_data = df['avgWTP_left'].to_numpy()\n",
    "r2_data = df['avgWTP_right'].to_numpy()\n",
    "# r1_data = [3]*num_data\n",
    "# r2_data = [3]*num_data\n",
    "\n",
    "seeds = np.random.SeedSequence(123).spawn(num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea8cafd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available jobs: 10\n",
      "Elapsed time: 80.278 seconds\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed, cpu_count, dump, load\n",
    "from data_utils import simulate_empirical_trial\n",
    "import time\n",
    "\n",
    "print(\"Available jobs:\", cpu_count())\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "dump(empirical_distributions, \"empirical.mmap\")\n",
    "empirical_distributions = load(\"empirical.mmap\", mmap_mode=\"r\")\n",
    "\n",
    "results = Parallel(n_jobs=-1, backend=\"loky\")(\n",
    "    delayed(simulate_empirical_trial)(\n",
    "        n,\n",
    "        r1_data,\n",
    "        r2_data,\n",
    "        empirical_distributions,\n",
    "        eta=eta,\n",
    "        kappa=kappa,\n",
    "        sigma=sigma,\n",
    "        a=a,\n",
    "        b=b,\n",
    "        T=T,\n",
    "        x0=x0,\n",
    "        dt=dt,\n",
    "        seed=seeds[n]\n",
    "    )\n",
    "    for n in range(num_data)\n",
    ")\n",
    "\n",
    "print(f\"Elapsed time: {time.time() - start:.3f} seconds\")\n",
    "\n",
    "# Store results\n",
    "decision_data = np.zeros((num_data, 2))\n",
    "flag_data = np.zeros(num_data)\n",
    "mu_data = [None] * num_data\n",
    "sacc_data = [None] * num_data\n",
    "\n",
    "for n, (decision, mu_array, sacc_array, r1, r2, flag) in enumerate(results):\n",
    "    decision_data[n] = decision\n",
    "    mu_data[n] = mu_array\n",
    "    sacc_data[n] = sacc_array\n",
    "    r1_data[n] = r1\n",
    "    r2_data[n] = r2\n",
    "    flag_data[n] = flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc6a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data = np.array([len(mu_array) for mu_array in mu_data])\n",
    "max_len = np.max(d_data)\n",
    "\n",
    "mu_data_padded = np.array([np.pad(mu_array, (0, max_len - len(mu_array)), mode='constant') for mu_array in mu_data])\n",
    "sacc_data_padded = np.array([np.pad(sacc_array, (0, max_len - len(sacc_array)), mode='constant') for sacc_array in sacc_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4df0bd",
   "metadata": {},
   "source": [
    "The cell below is a check to see if all the data needed for inference is generated. The source notebook for addm inference unpacks the same data, so this is a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ab2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_to_save = {\n",
    "#     'mu_array_padded_data': mu_data_padded, # Drift rates for each stage\n",
    "#     'sacc_array_padded_data': sacc_data_padded, # Saccade lengths for each stage\n",
    "#     'd_data': d_data, # Number of stages\n",
    "#     'decision_data': decision_data, # RT and choice\n",
    "#     'r1_data': r1_data, # avgWTP_left\n",
    "#     'r2_data': r2_data, # avgWTP_right\n",
    "#     'flag_data': flag_data.astype(np.int32), # Left choice first\n",
    "#     'eta': eta, # theta (multiplicative discount factor)\n",
    "#     'kappa': kappa, # drift\n",
    "#     'sigma': sigma, # noise\n",
    "#     'a': a, # initial boundary height\n",
    "#     'b': b, # linear boundary collapse rate\n",
    "#     'x0': x0, # initial diffusion distribution\n",
    "#     'T': T, # Maximum simulation horizon\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75763d",
   "metadata": {},
   "source": [
    "### Recovering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea1009cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import pickle\n",
    "import time\n",
    "import seaborn as sns\n",
    "from scipy.optimize import fmin, minimize, LinearConstraint, Bounds\n",
    "\n",
    "from efficient_fpt.multi_stage_cy import compute_loss_parallel, print_num_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4f4a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TYPE = np.float64\n",
    "\n",
    "# a = data[\"a\"]\n",
    "# b = data[\"b\"]\n",
    "# x0 = data[\"x0\"]\n",
    "# mu1_true = data[\"mu1\"] # Deprecated\n",
    "# mu2_true = data[\"mu2\"] # Deprecated\n",
    "eta_true = eta\n",
    "kappa_true = kappa\n",
    "# r1_data = data[\"r1_data\"]\n",
    "# r2_data = data[\"r2_data\"]\n",
    "flag_data = flag_data.astype(np.int32)\n",
    "\n",
    "# sigma = data[\"sigma\"]\n",
    "# T = data[\"T\"]\n",
    "\n",
    "mu1_true_data = kappa_true * (r1_data - eta_true * r2_data)\n",
    "mu2_true_data = kappa_true * (eta_true * r1_data - r2_data)\n",
    "\n",
    "mu_true_data = mu_data_padded.astype(DATA_TYPE)\n",
    "sacc_data = sacc_data_padded.astype(DATA_TYPE)\n",
    "length_data = d_data.astype(np.int32)\n",
    "rt_data = decision_data[:, 0].astype(DATA_TYPE)\n",
    "choice_data = decision_data[:, 1].astype(np.int32)\n",
    "\n",
    "num_data, max_d = mu_true_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e09842e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available threads: 10\n",
      "# data = 18758\n"
     ]
    }
   ],
   "source": [
    "print_num_threads()\n",
    "print(\"# data =\", num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37b01ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood evaluation time: 0.214 s\n"
     ]
    }
   ],
   "source": [
    "num_iter = 10\n",
    "start_time = time.time()\n",
    "for _ in range(num_iter):\n",
    "    loss = compute_loss_parallel(\n",
    "        mu1_true_data,\n",
    "        mu2_true_data,\n",
    "        rt_data,\n",
    "        choice_data,\n",
    "        flag_data,\n",
    "        sacc_data,\n",
    "        length_data,\n",
    "        max_d,\n",
    "        sigma,\n",
    "        a,\n",
    "        b,\n",
    "        x0,\n",
    "        num_threads=10,\n",
    "    )\n",
    "end_time = time.time()\n",
    "print(f\"Likelihood evaluation time: {(end_time - start_time) / num_iter:.3f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65a3f13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numerical optimization for eta, kappa, a, b, x0:\n",
      "Using trust-constr\n",
      "Initial guess: [0.5, 1, 1.0, 0.0, 0.0]\n",
      "\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 60, function evaluations: 396, CG iterations: 139, optimality: 6.32e-09, constraint violation: 0.00e+00, execution time: 8.7e+01 s.\n",
      "Total time: 88.414 seconds\n",
      "           message: `gtol` termination condition is satisfied.\n",
      "           success: True\n",
      "            status: 1\n",
      "               fun: 0.8105566071835106\n",
      "                 x: [ 9.917e-01  7.842e-01  1.523e+00  2.193e-01 -3.408e-01]\n",
      "               nit: 60\n",
      "              nfev: 396\n",
      "              njev: 66\n",
      "              nhev: 0\n",
      "          cg_niter: 139\n",
      "      cg_stop_cond: 4\n",
      "              grad: [-1.170e-06  1.490e-08 -2.445e-08  6.706e-08 -7.451e-09]\n",
      "   lagrangian_grad: [-6.434e-11  4.680e-09 -6.324e-09 -9.233e-10 -2.688e-09]\n",
      "            constr: [array([ 1.116e-01,  1.183e+00,  1.864e+00]), array([ 9.917e-01,  7.842e-01,  1.523e+00,  2.193e-01,\n",
      "                           -3.408e-01])]\n",
      "               jac: [array([[ 0.000e+00,  0.000e+00, ..., -6.439e+00,\n",
      "                             0.000e+00],\n",
      "                           [ 0.000e+00,  0.000e+00, ...,  0.000e+00,\n",
      "                             1.000e+00],\n",
      "                           [ 0.000e+00,  0.000e+00, ...,  0.000e+00,\n",
      "                            -1.000e+00]], shape=(3, 5)), array([[ 1.000e+00,  0.000e+00, ...,  0.000e+00,\n",
      "                             0.000e+00],\n",
      "                           [ 0.000e+00,  1.000e+00, ...,  0.000e+00,\n",
      "                             0.000e+00],\n",
      "                           ...,\n",
      "                           [ 0.000e+00,  0.000e+00, ...,  1.000e+00,\n",
      "                             0.000e+00],\n",
      "                           [ 0.000e+00,  0.000e+00, ...,  0.000e+00,\n",
      "                             1.000e+00]], shape=(5, 5))]\n",
      "       constr_nfev: [0, 0]\n",
      "       constr_njev: [0, 0]\n",
      "       constr_nhev: [0, 0]\n",
      "                 v: [array([ 1.209e-08,  4.711e-09, -5.227e-11]), array([ 1.170e-06, -1.022e-08,  1.380e-09,  9.862e-09,\n",
      "                            0.000e+00])]\n",
      "            method: tr_interior_point\n",
      "        optimality: 6.3239199303591954e-09\n",
      "  constr_violation: 0.0\n",
      "    execution_time: 87.05593013763428\n",
      "         tr_radius: 0.1\n",
      "    constr_penalty: 1.0\n",
      " barrier_parameter: 2.048000000000001e-09\n",
      " barrier_tolerance: 2.048000000000001e-09\n",
      "             niter: 60\n"
     ]
    }
   ],
   "source": [
    "# Constraint optimization for searching all parameters\n",
    "print(\"\\nNumerical optimization for eta, kappa, a, b, x0:\")\n",
    "method = \"trust-constr\"\n",
    "print(\"Using \" + method)\n",
    "func = lambda paras: compute_loss_parallel(\n",
    "    paras[1] * (r1_data - paras[0] * r2_data),\n",
    "    paras[1] * (paras[0] * r1_data - r2_data),\n",
    "    rt_data,\n",
    "    choice_data,\n",
    "    flag_data,\n",
    "    sacc_data,\n",
    "    length_data,\n",
    "    max_d,\n",
    "    sigma,\n",
    "    paras[2],\n",
    "    paras[3],\n",
    "    paras[4],\n",
    ")\n",
    "bounds = Bounds([0, 0, 0, 0, -np.inf], [1, np.inf, np.inf, np.inf, np.inf])\n",
    "con = LinearConstraint(\n",
    "    [[0, 0, 1, -np.max(rt_data), 0], [0, 0, 1, 0, 1], [0, 0, 1, 0, -1]],\n",
    "    lb=[0, 0, 0],\n",
    "    ub=[np.inf, np.inf, np.inf],\n",
    ")\n",
    "initial_guess = [0.5, 1, 1.0, 0.0, 0.0]\n",
    "print(\"Initial guess:\", initial_guess)\n",
    "print()\n",
    "start_time = time.time()\n",
    "paras_opt_result = minimize(\n",
    "    func,\n",
    "    x0=initial_guess,\n",
    "    bounds=bounds,\n",
    "    constraints=con,\n",
    "    method=method,\n",
    "    options={\"verbose\": 1},\n",
    ")\n",
    "print(f\"Total time: {time.time() - start_time:.3f} seconds\")\n",
    "print(paras_opt_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6a6b511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True and estimated value of parameters:\n",
      "eta: 0.50000, 0.99166\n",
      "kappa: 2.00000, 0.78418\n",
      "a: 2.10000, 1.52348\n",
      "b: 0.30000, 0.21928\n",
      "x0: 0.00000, -0.34076\n"
     ]
    }
   ],
   "source": [
    "mle = paras_opt_result[\"x\"]\n",
    "print(\"True and estimated value of parameters:\")\n",
    "print(f\"eta: {eta_true:.5f}, {mle[0]:.5f}\")\n",
    "print(f\"kappa: {kappa_true:.5f}, {mle[1]:.5f}\")\n",
    "print(f\"a: {a:.5f}, {mle[2]:.5f}\")\n",
    "print(f\"b: {b:.5f}, {mle[3]:.5f}\")\n",
    "print(f\"x0: {x0:.5f}, {mle[4]:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f4112b",
   "metadata": {},
   "source": [
    "Without proceeding onto further parameter recovery methods, I believe that having two methods (differential evolution and maximum likelihood estimation) converging on different parameters suggests that the data simulation process does not generate data identifiable to synthetic parameters. Specifically with this model, there is flexibility in collapsing bounds and initial condition, so it does not fit the class of model that I am using. From this, I have three thoughts. First, is it possible to map the transformation of values by carefully selecting different test points? Second, can I constrain the parameter space, like setting x0 to 0 or b to 0? Third, if the crux of the issue is truly the empirical simulation methodology, can some of the mystery be explained by finding out why middle fixations have value-modulated effects if they are sampled iid?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
